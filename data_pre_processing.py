# -*- coding: utf-8 -*-
"""Data_Pre-Processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qiIewZjCvrcROc4QwABY436jYJmOMQNp
"""

# Install SQLAlchemy since it's missing in the environment
!pip install SQLAlchemy
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('sqlite:////content/sample_data/job_posting_in_last_one_emonth.db')
sql = 'SELECT * FROM job_postings'
df = pd.read_sql(sql, engine)
df

import numpy as np

# Clean 'salary' to extract min and max salary
def extract_salary(s):
    try:
        if '-' in s:
            parts = s.replace('$', '').replace('/yr', '').replace(',', '').split('-')
            return float(parts[0]), float(parts[1])
        else:
            return np.nan, np.nan
    except:
        return np.nan, np.nan

# Apply the function to the 'salary' column and create new columns
df[['min_salary', 'max_salary']] = df['salary'].apply(lambda x: pd.Series(extract_salary(x)))
df['avg_salary'] = (df['min_salary'] + df['max_salary']) / 2
df[['min_salary', 'max_salary', 'avg_salary']]

# Group by 'experienceLevel', 'title', and 'sector' and fill NaN values in 'avg_salary' with the group mean
df['avg_salary'] = df.groupby(['experienceLevel', 'title', 'sector'])['avg_salary'].transform(lambda x: x.fillna(x.mean()))

# If there are still NaNs after groupby (e.g., a group has only NaNs), fill with the overall mean
df['avg_salary'] = df['avg_salary'].fillna(df['avg_salary'].mean())

# Convert to integers ONLY after ensuring no NaNs or inf
df['avg_salary'] = df['avg_salary'].astype(int) #This line should not have errors now.

df[['min_salary', 'max_salary', 'avg_salary']]

# Indices of rows to delete
indices_to_delete = [59, 69, 98, 166, 209, 840]

# Delete the rows
df = df.drop(indices_to_delete)

# Reset the index if needed
df = df.reset_index(drop=True)
df[['min_salary', 'max_salary', 'avg_salary']]

import pandas as pd
import re

def extract_skills_technologies(description):
    skills = []
    technologies = []

    # Regular expressions for skills and technologies (customize as needed)
    skills_pattern = r"\b(communication|problem-solving|leadership|teamwork|analytical|critical thinking|project management|time management|attention to detail|adaptability|collaboration|initiative|multitasking|decision making|interpersonal skills|presentation skills|troubleshooting|creativity|mentoring|stakeholder management)\b"
    technologies_pattern = r"\b(Python|Java|JavaScript|TypeScript|C\+\+|C#|R|SQL|NoSQL|MongoDB|PostgreSQL|MySQL|HTML|CSS|SASS|React|Angular|Vue\.js|Node\.js|Express|Django|Flask|Spring|Kubernetes|Docker|Terraform|Jenkins|Git|GitHub|GitLab|Bitbucket|AWS|Azure|Google Cloud|GCP|Firebase|Snowflake|Redshift|BigQuery|Databricks|Airflow|Power BI|Tableau|Looker|Qlik|Excel|MATLAB|TensorFlow|PyTorch|Scikit-learn|Pandas|NumPy|OpenCV|Hugging Face|NLP|Machine Learning|Deep Learning|Computer Vision|AI|REST API|GraphQL|Shell Scripting|Linux|Agile|Scrum|JIRA|CI/CD|Kafka|Spark|Hadoop|ETL|DBT|Apache Beam|Selenium|BeautifulSoup|FastAPI|LangChain|MLflow)\b"

    # Extract skills
    matches = re.findall(skills_pattern, description, re.IGNORECASE)
    skills.extend(matches)

    # Extract technologies
    matches = re.findall(technologies_pattern, description, re.IGNORECASE)
    technologies.extend(matches)

    return ", ".join(skills), ", ".join(technologies)

# Apply the function to the 'descriptionHtml' column
df[['skills', 'technologies']] = df['descriptionHtml'].astype(str).apply(lambda x: pd.Series(extract_skills_technologies(x)))

# Display the updated DataFrame
df[['skills', 'technologies']]

def remove_duplicates(text):
  if pd.isna(text):
    return text

  skills_list = [skill.strip() for skill in text.split(',')]
  unique_skills = list(set(skills_list))
  return ", ".join(unique_skills)


df['skills'] = df['skills'].apply(remove_duplicates)
df['technologies'] = df['technologies'].apply(remove_duplicates)

df[['skills', 'technologies']]

# prompt: add skills and technologies wherever it is empty or null based on 'experienceLevel', 'title', and 'sector'

# Group by 'experienceLevel', 'title', and 'sector'
grouped = df.groupby(['experienceLevel', 'title', 'sector'])

# Function to fill missing skills and technologies based on group mode
def fill_missing_skills_technologies(group):
    # Fill missing skills with the mode of skills in the group
    group['skills'] = group['skills'].fillna(group['skills'].mode()[0] if not group['skills'].mode().empty else '')
    # Fill missing technologies with the mode of technologies in the group
    group['technologies'] = group['technologies'].fillna(group['technologies'].mode()[0] if not group['technologies'].mode().empty else '')
    return group

# Apply the function to each group
df = grouped.apply(fill_missing_skills_technologies).reset_index(drop=True)

# Display the updated DataFrame
df[['skills', 'technologies']]

def replace_not_applicable_experience(row):
    if row['experienceLevel'] == 'Not Applicable':
        if 'entry level' in row['descriptionHtml'].lower():
            return 'Entry level'
        elif 'mid level' in row['descriptionHtml'].lower() or 'intermediate' in row['descriptionHtml'].lower():
            return 'Mid-Senior level'
        elif 'senior' in row['descriptionHtml'].lower() or 'lead' in row['descriptionHtml'].lower() or 'principal' in row['descriptionHtml'].lower():
            return 'Senior level'
        else:
            # Default to Entry level if no other keywords are found
            return 'Entry level'
    return row['experienceLevel']


df['experienceLevel'] = df.apply(replace_not_applicable_experience, axis=1)

# Keep only specified columns
columns_to_keep = ['title', 'companyName', 'location', 'contractType', 'experienceLevel', 'workType', 'sector', 'avg_salary', 'skills', 'technologies']
df = df[columns_to_keep]

# Export to Excel
df.to_excel('processed_job_postings.xlsx', index=False)